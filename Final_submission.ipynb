{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d92a616",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1203b4d1",
   "metadata": {},
   "source": [
    "You are a very inexperienced adventurer, just starting off on your first of what is sure to\n",
    "be many, many adventures! Soon after excitedly leaving your first tavern, you find the flash\n",
    "drive of a past adventurer who met an unfortunate demise.\n",
    "On it, there is a calculator (privoro_monster_calc.py) that appears to calculate the\n",
    "probability of you winning a fight against a monster, given the monster’s information and\n",
    "the dead adventurer. You also find what appears to be a datasheet containing past examples\n",
    "(monsters_list.csv) on which the calculator was trained.\n",
    "While you are happy to have come across this data, given how you found this calculator,\n",
    "you decide to give the calculator code a once over before using it for yourself, suspecting\n",
    "that it may have materially contributed to the...deadness of the adventurer you’ve stumbled\n",
    "across."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9d924",
   "metadata": {},
   "source": [
    "### Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac814cb3",
   "metadata": {},
   "source": [
    "Your goal is to fix the calculator in any way you see fit. You may change any code and you\n",
    "are permitted to use numpy, pandas, or scipy if you wish. When changing code, you should\n",
    "try to make the code more pythonic and concise where possible, yet also maintain readability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b6669",
   "metadata": {},
   "source": [
    "Please do not use libraries like PyTorch, scikit-learn, or tensorflow here, as they are not\n",
    "needed. Note that there is no single correct answer. The goal is to make the code clean and\n",
    "readable.\n",
    "Estimated time to complete this problem: 1-2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8083ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e5564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dist(data):\n",
    "#     1. Commented unnecessary creation of two variables\n",
    "#     mu = np.mean(data)\n",
    "#     std = np.std(data)\n",
    "    return norm(np.mean(data), np.std(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0aa5988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_of_class(prior, dists, data):\n",
    "    prob = prior\n",
    "    for i in range(len(dists)):\n",
    "        prob *= dists[i].pdf(data[i])\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "670d130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(p_w, dists_win, data):\n",
    "    p_winning = prob_of_class(p_w, dists_win, data)\n",
    "    p_losing = 1 - p_winning\n",
    "\n",
    "    answer = 0\n",
    "    if p_winning > p_losing:\n",
    "        answer = 1\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96d2f7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(p_w, dists_win, win, lost):\n",
    "    correct = 0\n",
    "    total = len(win) + len(lost)\n",
    "    for d in win:\n",
    "        guess = predict(p_w, dists_win, d)\n",
    "        if guess == 1:\n",
    "            correct += 1\n",
    "    \n",
    "    for d in lost:\n",
    "        guess = predict(p_w, dists_win, d)\n",
    "        if guess == 0:\n",
    "            correct += 1\n",
    "\n",
    "    print(f'Acc: {correct/total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1edb9f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data\n",
    "monster_df = pd.read_csv(\"monster_list.csv\")\n",
    "\n",
    "# calculate the prior\n",
    "# 2. Corrected the column name\n",
    "winning = monster_df['monster_defeated'].to_numpy()\n",
    "\n",
    "# 3. Simplified the process of obtaining the winning probability \n",
    "# p_winning = 0\n",
    "# for i in winning:\n",
    "#     if i == 1:\n",
    "#         p_winning += 1\n",
    "\n",
    "# p_winning = p_winning / len(winning)\n",
    "p_winning = winning.mean()\n",
    "\n",
    "#split the data\n",
    "data = monster_df.drop(columns=['monster_name', 'monster_defeated']).to_numpy()\n",
    "train_win = data[winning == 1]\n",
    "\n",
    "# 4. Replaced assignment operator with relational operator \n",
    "train_lost = data[winning == 0]\n",
    "\n",
    "# 5. Combined identical blocks of code in a loop for iterating for each feature \n",
    "for j in range(train_win.shape[1]):\n",
    "    col_data = []\n",
    "    \n",
    "    for i in range(len(train_win)):\n",
    "        col_data.append(train_win[i][j])\n",
    "    exec(f'win_p{j+1} = create_dist(col_data)')\n",
    "\n",
    "\n",
    "win_pdfs = [win_p1, win_p2, win_p3, win_p4, win_p5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1798a18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "test_monsters = pd.read_csv('monster_list_test.csv')\n",
    "\n",
    "# 6. Replaced to_list() with to_numpy() as to_list() is for pd.Series\n",
    "test_data = test_monsters.drop(columns=['monster_name', 'monster_defeated']).to_numpy()\n",
    "test_winning = test_monsters['monster_defeated'].to_numpy()\n",
    "\n",
    "test_win = test_data[test_winning == 1]\n",
    "test_lost = test_data[test_winning == 0]\n",
    "\n",
    "#test it out\n",
    "calc_acc(p_w = p_winning, dists_win = win_pdfs, win = test_win, lost = test_lost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2f9832",
   "metadata": {},
   "source": [
    "The fixes done by me have been indicated through comments in the above code. Apart from the aforementioned changes, I have also improved the readability by adding spacing between operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0652cc6",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59becc95",
   "metadata": {},
   "source": [
    "### Fixing Calculator Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badaa82f",
   "metadata": {},
   "source": [
    "Note: Please do not complete this section until the previous part is complete; this is a bonus\n",
    "and not required.\n",
    "1\n",
    "The logic behind the calculator is broken. There is a logical error in the way certain\n",
    "probabilities are calculated and after fixing it, the test set (monster_list_test.csv) accu\u0002racy should be 100%. Note that you do not need to compute priors for each type of monster,\n",
    "just the prior for winning overall. Fixing the logical error is sufficient to get 100% accuracy\n",
    "on the test set.\n",
    "\n",
    "• Fix the logic in the calculator.\n",
    "\n",
    "• Please write a (very) short description of what you changed and why. 2-3 sentences is\n",
    "sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e9a6e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5192c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dist(data):\n",
    "    return norm(np.mean(data), np.std(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9981ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_of_class(prior, dists, data):\n",
    "    prob = prior\n",
    "    for i in range(len(dists)):\n",
    "        prob *= dists[i].pdf(data[i])\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cac31bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(p_w, dists_win, dists_lost, data):\n",
    "    p_winning = prob_of_class(p_w, dists_win, data)\n",
    "    \n",
    "    # 1. Modified the way of calculating the probability of losing\n",
    "    # For more details, please refer to the desciption below\n",
    "    p_losing = prob_of_class(1 - p_w, dists_lost, data)\n",
    "\n",
    "    answer = 0\n",
    "    if p_winning > p_losing:\n",
    "        answer = 1\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "107c1a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(p_w, dists_win, dists_lost, win, lost):\n",
    "    correct = 0\n",
    "    total = len(win) + len(lost)\n",
    "    for d in win:\n",
    "        guess = predict(p_w, dists_win, dists_lost, d)\n",
    "        if guess == 1:\n",
    "            correct += 1\n",
    "    \n",
    "    for d in lost:\n",
    "        guess = predict(p_w, dists_win, dists_lost, d)\n",
    "        if guess == 0:\n",
    "            correct += 1\n",
    "\n",
    "    print(f'Acc: {correct/total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fca9f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data\n",
    "monster_df = pd.read_csv(\"monster_list.csv\")\n",
    "\n",
    "# calculate the prior\n",
    "winning = monster_df['monster_defeated'].to_numpy()\n",
    "p_winning = winning.mean()\n",
    "\n",
    "#split the data\n",
    "data = monster_df.drop(columns = ['monster_name', 'monster_defeated']).to_numpy()\n",
    "train_win = data[winning == 1]\n",
    "train_lost = data[winning == 0]\n",
    "\n",
    "for j in range(train_win.shape[1]):\n",
    "    col_data = []\n",
    "    \n",
    "    for i in range(len(train_win)):\n",
    "        col_data.append(train_win[i][j])\n",
    "    exec(f'win_p{j+1} = create_dist(col_data)')\n",
    "\n",
    "# 2. Creating dist for training data where the adventurer lost\n",
    "for j in range(train_lost.shape[1]):\n",
    "    col_data = []\n",
    "    \n",
    "    for i in range(len(train_lost)):\n",
    "        col_data.append(train_lost[i][j])\n",
    "    exec(f'lost_p{j+1} = create_dist(col_data)')\n",
    "\n",
    "\n",
    "win_pdfs = [win_p1, win_p2, win_p3, win_p4, win_p5]\n",
    "lost_pdfs = [lost_p1, lost_p2, lost_p3, lost_p4, lost_p5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05ce6566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_monsters = pd.read_csv('monster_list_test.csv')\n",
    "test_data = test_monsters.drop(columns=['monster_name', 'monster_defeated']).to_numpy()\n",
    "test_winning = test_monsters['monster_defeated'].to_numpy()\n",
    "\n",
    "test_win = test_data[test_winning == 1]\n",
    "test_lost = test_data[test_winning == 0]\n",
    "\n",
    "#test it out\n",
    "calc_acc(p_w = p_winning, dists_win = win_pdfs, dists_lost = lost_pdfs, win = test_win, lost = test_lost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe3be9c",
   "metadata": {},
   "source": [
    "The above block contains the fixed calculator logic. The problem with the earlier approach was that we were working with probability density functions (norm.pdf(x)) of each feature instead of considering their actual probabilities. To convert PDFs to probabilities, we might want to integrate the PDFs with limits being the interval or a simple approximation would be to mulitply PDF with the length of the Interval under consideration. Even with the assumption that our PDFs are continous, we may not have a true equality owing to the fact that the PDF values may vary over that interval under consideration. Also, when we compute the PDF of a particular datapoint, we cannot ask for the probability that X is an single integer (`P(X = x) = 0` for any real number x). Instead, we may see that as the probability that x is close to a single number.\n",
    "\n",
    "Considering all these points, the `p_winning` that was computed earlier does not yield the actual probability of winning. It was computed by multiplying the prior for winning overall and the PDFs of each feature. Which is why `1 - p_winning` will not give `p_losing`.And, since prior probability is less than 0.5, irrespective of what my other probabilities are, the final probability will always be less than 0.5 classifying all the results as a loss. \n",
    "\n",
    "So, For obtaining `p_losing`, I've leveraged the data where the adventurer lost to the monster to get the mean and stand deviation of the distribution for each feature and essentially repeating the same steps we followed while computing `p_winning` except for the fact that the prior probabibility here would be of losing overall. After computing both `p_winning` and `p_losing`, I'm comparing their probabibility values to check which one's higher and assigning the appropriate outcome as my predicition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0235dce1",
   "metadata": {},
   "source": [
    "### Picking a new classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a6d8dd",
   "metadata": {},
   "source": [
    "Note: Please do not complete this section until the other parts are complete; this is a bonus\n",
    "and not required.\n",
    "In this section, suppose you are given the freedom to implement any kind of classifier\n",
    "you wish. All libraries are now fair game, including PyTorch, scikit-learn, and tensorflow.\n",
    "\n",
    "• What method would you use to predict your chances of survival against a given monster,\n",
    "and how would you (at a high level) set it up?\n",
    "\n",
    "• Why is that method superior to the (attempted) method in the original calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a1cbd5",
   "metadata": {},
   "source": [
    "#### Response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3324ccd0",
   "metadata": {},
   "source": [
    "**What method would you use to predict your chances of survival against a given monster, and how would you (at a high level) set it up?**\n",
    "\n",
    "If we are going to use Machine Learning models, our objective should be to generalize the pattern while training. Especially for smaller datasets, the chances of overfitting is quite high which can result in poor test accuracy. So, inorder to avoid overfitting, we should go with simple models rather than using complex neural networks(which requires a large training set to perform better). \n",
    "\n",
    "I would start with something as simple as a Logistic regression or a tree based model like XGBoost or a combination of both of these models.We might also model this data with Naive Bayes, Linear SVC. \n",
    "\n",
    "**Why is that method superior to the (attempted) method in the original calculator?**\n",
    "\n",
    "The original calculator uses Probabibility Density estimates to approximate the probability of observing a win or loss against a monster. This may not only be less accurate but also can be quite prone to outliers. \n",
    "\n",
    "Logistic Regression on the other hand is not affected by this problem. Since, it is a simple model it'll not try to learn the noise or errors present in the data. The regularization feature bolsters this further by penalizing in cases where we have correlated features. \n",
    "\n",
    "A Tree based classifier like XGBoost on the other hand can be used with smaller depths to avoid overfitting. Advantages includes flexibiliy, ability to run parallel processes, inbuilt missing data handler\n",
    "\n",
    "Or we may also employ a combination of both Logistic Regression and XGBoost models(this helps in variance reduction and hence will be able to generalize better).\n",
    "\n",
    "I'll illustrate the aforementioned approaches below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa0ccc9",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1aa07e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb9fef01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monster_df = pd.read_csv(\"monster_list.csv\")\n",
    "winning = monster_df['monster_defeated'].to_numpy()\n",
    "data = monster_df.drop(columns = ['monster_name', 'monster_defeated']).to_numpy()\n",
    "\n",
    "#Using L2 Regularization along with inverse of regularization strength as parameters\n",
    "#Setting a small value for 'C' will yield stronger regularization\n",
    "lr = LogisticRegression(penalty = 'l2', C = 0.1)\n",
    "lr.fit(data, winning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d6bfd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_monsters = pd.read_csv('monster_list_test.csv')\n",
    "test_data = test_monsters.drop(columns=['monster_name', 'monster_defeated']).to_numpy()\n",
    "test_winning = test_monsters['monster_defeated'].to_numpy()\n",
    "\n",
    "x = lr.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54a33020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_winning, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc075475",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4670030b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmanoger\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2524a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:51:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmanoger\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eta=0.8, gamma=2, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.800000012,\n",
       "              max_delta_step=0, max_depth=2, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0.5, reg_lambda=0.5, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monster_df = pd.read_csv(\"monster_list.csv\")\n",
    "winning = monster_df['monster_defeated'].to_numpy()\n",
    "data = monster_df.drop(columns = ['monster_name', 'monster_defeated']).to_numpy()\n",
    "\n",
    "#Using lesser max_depth to avoid overfitting, making model more conservative with \n",
    "#high gamma and eta values along with regularization \n",
    "xgb = XGBClassifier(max_depth=2, gamma=2, eta=0.8, reg_alpha=0.5, reg_lambda=0.5)\n",
    "xgb.fit(data, winning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "392de4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_monsters = pd.read_csv('monster_list_test.csv')\n",
    "test_data = test_monsters.drop(columns=['monster_name', 'monster_defeated']).to_numpy()\n",
    "test_winning = test_monsters['monster_defeated'].to_numpy()\n",
    "\n",
    "x = xgb.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26746c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_winning, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01b5f6e",
   "metadata": {},
   "source": [
    "#### Combination of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "daaf687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "monster_df = pd.read_csv(\"monster_list.csv\")\n",
    "winning = monster_df['monster_defeated'].to_numpy()\n",
    "data = monster_df.drop(columns = ['monster_name', 'monster_defeated']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2330ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_monsters = pd.read_csv('monster_list_test.csv')\n",
    "test_data = test_monsters.drop(columns=['monster_name', 'monster_defeated']).to_numpy()\n",
    "test_winning = test_monsters['monster_defeated'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "982a4033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmanoger\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:51:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [LogisticRegression(penalty = 'l2', C = 0.1),\n",
    "          XGBClassifier(max_depth=2, gamma=2, eta=0.8, reg_alpha=0.5, reg_lambda=0.5)]\n",
    "\n",
    "preds = pd.DataFrame()\n",
    "for i, m in enumerate(models):\n",
    "    m.fit(data, winning)\n",
    "    preds[i] = m.predict_proba(test_data)[:,1]\n",
    "\n",
    "weights = [1, 0.4]\n",
    "# Calculating the weighted probabilities with weightage '1' for Logistic Regression  \n",
    "# and'0.4' for XGBoost\n",
    "preds['weighted_pred'] = (preds * weights).sum(axis=1) / sum(weights)\n",
    "\n",
    "#Taking all predictions probabilities over 0.5 as label 1\n",
    "x = preds['weighted_pred'] > 0.5\n",
    "x = x.values.astype(int)\n",
    "accuracy_score(test_winning, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
